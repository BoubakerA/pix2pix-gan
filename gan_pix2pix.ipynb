{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to image translation: pix2pix gan\n",
    "Pix2pix gans are a sort of gans that are able to learn the mapping from between pairs of images. For example it can learn to transfrom black and white images into colorful images, turn google map photos into aerial images and also turn drawings into colourful images. \n",
    "This notebook is an attempt to train a pix2pix gan that learn the mapping between the drawing of a shoe and the actual RGB image of the shoe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    width = tf.shape(image)[1]\n",
    "    width_half = width//2\n",
    "\n",
    "    input_image = image[:,:width_half,:]\n",
    "    target_image = image[:,width_half:,:]\n",
    "\n",
    "    input_image = tf.cast(input_image, dtype=tf.float32) \n",
    "    target_image = tf.cast(target_image, dtype=tf.float32)\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, target_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    target_image = (target_image / 127.5) - 1\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(image_path):\n",
    "    input_image, target_image = read_image(image_path)\n",
    "    input_image, target_image = normalize(input_image, target_image)\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/basaadi/projects/gan_trans/data/train\"\n",
    "sample_paths = glob.glob(train_dir+\"/*.jpg\")\n",
    "test_sample_paths = sample_paths[1000:1100]\n",
    "sample_paths = sample_paths[:1000]\n",
    "print(f\"len sample paths : {len(sample_paths)}\")\n",
    "print(f\"len test_sample_paths  : {len(test_sample_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = random.choice(sample_paths)\n",
    "input_image, target_image = preprocess_fn(sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(input_image)\n",
    "axs[1].imshow(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(sample_paths)\n",
    "train_dataset = train_dataset.map(preprocess_fn, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(100)\n",
    "train_dataset = train_dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition du modele\n",
    "class Block(tf.keras.layers.Layer):\n",
    "    def __init__(self,  out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(out_ch, (4, 4), 2,kernel_initializer='he_normal', padding='same')\n",
    "        self.BatchNormalization1 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu1  = tf.keras.layers.LeakyReLU(alpha=0.01)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.BatchNormalization1(x)\n",
    "        x = self.leaky_relu1(x)\n",
    "        return x\n",
    "        \n",
    "    def model(self, input_shape):\n",
    "        x = tf.keras.Input(input_shape)\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = Block(30)\n",
    "print(block.model((256,256,1)).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(tf.keras.layers.Layer):    \n",
    "    def __init__(self, chs=(32,64, 128, 256, 512)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = [Block(ch) for ch in chs]\n",
    "    \n",
    "    def call(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "        return ftrs\n",
    "        \n",
    "    def model(self, input_shape):\n",
    "        x = tf.keras.Input(input_shape)\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(chs=(64, 128, 256, 512, 512, 512, 512, 512))\n",
    "input = tf.ones((1,256,256,3))\n",
    "enc_ftrs = encoder(input)\n",
    "# print(encoder.model((256,256,1)).summary())\n",
    "for enc_ftr in enc_ftrs:\n",
    "    print(enc_ftr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "# class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, chs=(64, 32, 16)):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = [tf.keras.layers.Conv2DTranspose(ch, (4, 4), strides=(2, 2), padding='same') for ch in chs[1:]]\n",
    "        self.dec_blocks = [Block(chs[i]) for i in range(1, len(chs))]\n",
    "        \n",
    "    def call(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            x        = tf.keras.layers.concatenate([x, encoder_features[i]])\n",
    "        return x\n",
    "        \n",
    "    def model(self, input_shape):\n",
    "        x = tf.keras.Input(input_shape)\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ftrs[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(chs=(512, 512, 512, 512, 512, 256, 128, 64))\n",
    "dec_ftr = decoder(enc_ftrs[-1], enc_ftrs[::-1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self, enc_chs=(64, 128, 256, 512, 512, 512, 512, 512), dec_chs=(512,512,512,512,512, 256, 128, 64),num_channels=3):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.conv = tf.keras.layers.Conv2DTranspose(num_channels, (4, 4), strides=(2, 2), padding='same')\n",
    "\n",
    "    def call(self, x):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.conv(out)\n",
    "        return out\n",
    "    \n",
    "    def model(self, input_shape):\n",
    "        x = tf.keras.Input(shape=input_shape)\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.build(input_shape=(1,256,256,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self, enc_chs=[64,128,256]):\n",
    "        super().__init__()\n",
    "        self.initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "        self.zero_pad1 = tf.keras.layers.ZeroPadding2D()\n",
    "        self.zero_pad2 = tf.keras.layers.ZeroPadding2D()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=self.initializer, use_bias=False)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=self.initializer, activation='sigmoid')\n",
    "        \n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "        self.enc_blocks = [Block(ch) for ch in enc_chs]\n",
    "\n",
    "    def call(self, x1, x2):\n",
    "        x = tf.keras.layers.concatenate([x1, x2])\n",
    "        for enc_block in self.enc_blocks:\n",
    "            x = enc_block(x)\n",
    "        \n",
    "        x = self.zero_pad1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.zero_pad2(x)\n",
    "        output = self.conv2(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def model(self, input_shape=[256,256,3]):\n",
    "        x1 = tf.keras.Input(shape=input_shape)\n",
    "        x2 = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "        return tf.keras.Model(inputs=[x1,x2], outputs=self.call(x1,x2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(enc_chs=[64,128,256])\n",
    "print(discriminator.model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target, real_labels):\n",
    "    Lambda = 100\n",
    "\n",
    "    loss1 = tf.keras.losses.BinaryCrossentropy()\n",
    "    loss2 = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    bce_loss = loss1(real_labels, disc_generated_output)  \n",
    "    l1_loss = loss2(target, gen_output)\n",
    "\n",
    "    total_gen_loss = bce_loss + Lambda*l1_loss\n",
    "\n",
    "    return total_gen_loss, bce_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output, real_labels, fake_labels):\n",
    "\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    bce_loss_real = loss(real_labels, disc_real_output)\n",
    "    bce_loss_fake = loss(fake_labels, disc_generated_output)\n",
    "    total_loss = bce_loss_real + bce_loss_fake\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam((2e-4), beta_1=0.5, beta_2=0.999)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam((2e-4), beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    input_image, target = inputs\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator(input_image, target)\n",
    "\n",
    "        disc_generated_output = discriminator(input_image, gen_output, training=True)\n",
    "        \n",
    "        real_targets = tf.ones_like(disc_real_output)\n",
    "        fake_targets = tf.zeros_like(disc_real_output)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, l1_loss = generator_loss(disc_generated_output, gen_output, target, real_targets)\n",
    "\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output, real_targets, fake_targets)\n",
    "\n",
    "        gen_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
    "\n",
    "        return gen_gan_loss, l1_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "def fit():\n",
    "    for epoch in range(EPOCHS):\n",
    "        num_batches = 0\n",
    "        gan_loss, l1_loss, disc_loss = 0, 0, 0\n",
    "        for dist_inputs in train_dataset:\n",
    "            num_batches +=1\n",
    "            gan_l, l1_l, disc_l = train_step(dist_inputs)\n",
    "            gan_loss += gan_l\n",
    "            l1_loss += l1_l\n",
    "            disc_loss += disc_l\n",
    "\n",
    "        gan_loss = gan_loss/num_batches\n",
    "        l1_loss = l1_loss/num_batches\n",
    "        disc_loss = disc_loss/num_batches\n",
    "\n",
    "        print(f\"Epoch: {epoch}: D_Loss: {disc_loss}: G_Loss: {gan_loss}: l1_loss: {l1_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.save_weights('gen'+str(100)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_sample_paths)\n",
    "test_dataset = test_dataset.map(preprocess_fn, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.shuffle(100)\n",
    "test_dataset = test_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "generator.build((1,256,256,3))\n",
    "generator.load_weights(\"gen100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, target in test_dataset.take(1):\n",
    "    preds = generator(img, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "axs[0].imshow(img[0,:,:,:])\n",
    "axs[1].imshow(preds[0,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sources\n",
    "https://learnopencv.com/paired-image-to-image-translation-pix2pix/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c53109e521fc789122ce000cac189121e9080f7196eef2392df03f2361de8356"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ai': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
